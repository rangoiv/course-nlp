{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d6e97f",
   "metadata": {},
   "source": [
    "## Predvidanje brojeva uz transformere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ccae09",
   "metadata": {},
   "source": [
    "## Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e58ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "intToStrMap = {\n",
    "    0: \"nula\",\n",
    "    1: \"jedan\",\n",
    "    2: \"dva\",\n",
    "    3: \"tri\",\n",
    "    4: \"četiri\",\n",
    "    5: \"pet\",\n",
    "    6: \"šest\",\n",
    "    7: \"sedam\",\n",
    "    8: \"osam\",\n",
    "    9: \"devet\",\n",
    "    10: \"deset\",\n",
    "    11: \"jedanaest\",\n",
    "    12: \"dvanaest\",\n",
    "    13: \"trinaest\",\n",
    "    14: \"četrnaest\",\n",
    "    15: \"petnaest\",\n",
    "    16: \"šesnaest\",\n",
    "    17: \"sedamnaest\",\n",
    "    18: \"osamnaest\",\n",
    "    19: \"devetnaest\",\n",
    "    20: \"dvadeset\",\n",
    "    30: \"trideset\",\n",
    "    40: \"četrdeset\",\n",
    "    50: \"pedeset\",\n",
    "    60: \"šezdeset\",\n",
    "    70: \"sedamdeset\",\n",
    "    80: \"osamdeset\",\n",
    "    90: \"devedeset\",\n",
    "    100: \"sto\",\n",
    "    200: \"dvjesto\",\n",
    "    300: \"tristo\",\n",
    "    400: \"četiristo\",\n",
    "    500: \"petsto\",\n",
    "    600: \"šesto\",\n",
    "    700: \"sedamsto\",\n",
    "    800: \"osamsto\",\n",
    "    900: \"devetsto\",\n",
    "}\n",
    "\n",
    "koliko = intToStrMap.copy()\n",
    "koliko[1] = \"jedna\"\n",
    "koliko[2] = \"dvije\"\n",
    "\n",
    "\n",
    "\n",
    "def intToStr(x: int, kol=False):\n",
    "    if kol and x <= 20: return koliko[x]\n",
    "    if x <= 20: return intToStrMap[x]\n",
    "    if x < 100: return f\"{intToStrMap[x//10 * 10]}{' '+intToStr(x%10, kol) if x%10 else ''}\"\n",
    "    if x < 1000: return f\"{intToStrMap[x//100 * 100]}{' '+intToStr(x%100, kol) if x%100 else ''}\"\n",
    "    if x <= 100000: \n",
    "        tisucice = 'tisuću' if x//1000 == 1 else f\"{intToStr(x//1000, True)} tisuć{'e' if (x//1000)%10 < 5 else 'a'}\"\n",
    "        return f\"{tisucice}{' '+intToStr(x%1000) if x%1000 else ''}\"\n",
    "    raise Exception(\"Didnt except number bigger than 10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9e59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ', '.join(intToStr(i) for i in range(1,100001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf85378",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2c1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b080f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ddee2",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Using BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d729771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tokenizers\n",
    "from tokenizers import trainers, Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import decoders\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a75acd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Tokenizer\n",
    "tokenizer = Tokenizer(BPE())\n",
    "\n",
    "# Define a pre-tokenizer to split text into words (Croatian usually uses whitespace)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Initialize a trainer for BPE\n",
    "trainer = BpeTrainer(special_tokens=[\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\"])\n",
    "\n",
    "# Tokenize the text and add it to the trainer\n",
    "tokenizer.train_from_iterator([text], trainer=trainer)\n",
    "\n",
    "# Save the trained tokenizer and its vocabulary\n",
    "tokenizer.save(\"custom_croatian_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc7b4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [85, 5, 50, 5, 48, 5, 71, 5, 51, 5, 70, 5, 45, 5, 44, 5, 52, 5, 27, 5, 96, 5, 92, 5, 91, 5, 55, 54]\n",
      "Tokens: ['jedan', ',', 'dva', ',', 'tri', ',', 'četiri', ',', 'pet', ',', 'šest', ',', 'sedam', ',', 'osam', ',', 'devet', ',', 'deset', ',', 'jedanaest', ',', 'dvanaest', ',', 'trinaest', ',', 'četr', 'na']\n",
      "Decoded Text: jedan,dva,tri,četiri,pet,šest,sedam,osam,devet,deset,jedanaest,dvanaest,trinaest,četrna\n"
     ]
    }
   ],
   "source": [
    "# Load the trained tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"custom_croatian_tokenizer.json\")\n",
    "\n",
    "# Tokenize a sentence\n",
    "sentence = text[:100]\n",
    "encoding = tokenizer.encode(sentence)\n",
    "\n",
    "# Print token IDs and tokens\n",
    "print(\"Token IDs:\", encoding.ids)\n",
    "print(\"Tokens:\", encoding.tokens)\n",
    "\n",
    "# Decode the tokens\n",
    "decoded_text = encoding.tokens\n",
    "decoded_text = decoders.BPEDecoder().decode(decoded_text)\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43449ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4039009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa67b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNumberDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, seq_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = tokenizer.encode(text)\n",
    "        self.textids = torch.tensor(self.text.ids, device=device)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.text) - self.seq_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.textids[idx: idx+self.seq_len]\n",
    "        target = self.textids[idx+1: idx+self.seq_len+1]\n",
    "        return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8f43e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=1, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('jedan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a23630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0aa9fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "batch_size = 64\n",
    "ds = CustomNumberDataset(text, tokenizer, seq_len)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d360beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([64, 50]) torch.Size([64, 50])\n",
      "2 torch.Size([64, 50]) tensor([61, 44,  5,  ..., 75, 64,  5], device='cuda:0')\n",
      ">> Input:  tristo devedeset osam , osamdeset pet tisuća tristo devedeset devet , osamdeset pet tisuća četiristo , osamdeset pet tisuća četiristo jedan , osamdeset pet tisuća četiristo dva , osamdeset pet tisuća četiristo tri , osamdeset pet tisuća četiristo četiri , osamdeset pet tisuća četiristo pet , osamdeset pet tisuća četiristo\n",
      ">> Target:  devedeset osam , osamdeset pet tisuća tristo devedeset devet , osamdeset pet tisuća četiristo , osamdeset pet tisuća četiristo jedan , osamdeset pet tisuća četiristo dva , osamdeset pet tisuća četiristo tri , osamdeset pet tisuća četiristo četiri , osamdeset pet tisuća četiristo pet , osamdeset pet tisuća četiristo šest\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dl):\n",
    "    inp, target = batch\n",
    "    print(len(batch), inp.shape, target.shape)\n",
    "    print(len(batch), inp.shape, target.reshape(-1))\n",
    "    print('>> Input: ', tokenizer.decode(list(inp[0])))\n",
    "    print('>> Target: ', tokenizer.decode(list(target[0])))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6466c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc014417",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "620394cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        debug = False\n",
    "        if debug: print(1, src.shape)\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        if debug: print(2, src.shape)\n",
    "        src = self.pos_encoder(src)\n",
    "        if debug: print(3, src.shape)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        if debug: print(4, output.shape)\n",
    "        output = self.linear(output)\n",
    "        if debug: print(5, output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10c62284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 100  # embedding dimension\n",
    "d_hid = 50  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75e731db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.5490, -0.1069,  ..., -0.6378,  0.1903,  0.9390],\n",
       "         [-0.5654,  0.5119, -0.0684,  ...,  0.6576,  0.2072, -0.0461],\n",
       "         [ 0.4379,  0.3032,  0.9007,  ...,  0.1713, -0.4838,  1.2636],\n",
       "         ...,\n",
       "         [-0.1289,  0.6524, -0.2970,  ...,  0.5821,  0.4482,  0.2781],\n",
       "         [ 0.2764,  0.1889, -0.1402,  ..., -0.0114,  0.2077,  0.6134],\n",
       "         [-0.1798,  0.5263,  0.2828,  ..., -0.6464, -0.5283, -0.0115]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([51, 42, 75, 62, 70,  5, 66, 51, 42, 75, 62, 45,  5, 66, 51, 42, 75, 62,\n",
    "        44,  5, 66, 51, 42, 75, 62, 52,  5, 66, 51, 42, 75, 61,  5, 66, 51, 42,\n",
    "        75, 61, 85,  5, 66, 51, 42, 75, 61],\n",
    "       device='cuda:0').unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d1919c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ece0720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 - 0/9843, Loss: 0.03940067067742348, Accuracy 0.0\n",
      "Epoch: 1 - 500/9843, Loss: 0.04529324173927307, Accuracy 98.63672637939453\n",
      "Epoch: 1 - 1000/9843, Loss: 0.036231495440006256, Accuracy 98.65469360351562\n",
      "Epoch: 1 - 1500/9843, Loss: 0.03598722442984581, Accuracy 98.6467056274414\n",
      "Epoch: 1 - 2000/9843, Loss: 0.05168401822447777, Accuracy 98.63273620605469\n",
      "Epoch: 1 - 2500/9843, Loss: 0.044929951429367065, Accuracy 98.65469360351562\n",
      "Epoch: 1 - 3000/9843, Loss: 0.04474151134490967, Accuracy 98.65269470214844\n",
      "Epoch: 1 - 3500/9843, Loss: 0.046152301132678986, Accuracy 98.6467056274414\n",
      "Epoch: 1 - 4000/9843, Loss: 0.028442008420825005, Accuracy 98.6487045288086\n",
      "Epoch: 1 - 4500/9843, Loss: 0.06017894297838211, Accuracy 98.64071655273438\n",
      "Epoch: 1 - 5000/9843, Loss: 0.03350934013724327, Accuracy 98.65668487548828\n",
      "Epoch: 1 - 5500/9843, Loss: 0.03283650055527687, Accuracy 98.65269470214844\n",
      "Epoch: 1 - 6000/9843, Loss: 0.03433560952544212, Accuracy 98.67465209960938\n",
      "Epoch: 1 - 6500/9843, Loss: 0.046673644334077835, Accuracy 98.66267395019531\n",
      "Epoch: 1 - 7000/9843, Loss: 0.04252307489514351, Accuracy 98.67066192626953\n",
      "Epoch: 1 - 7500/9843, Loss: 0.045872047543525696, Accuracy 98.65668487548828\n",
      "Epoch: 1 - 8000/9843, Loss: 0.052072349935770035, Accuracy 98.65868377685547\n",
      "Epoch: 1 - 8500/9843, Loss: 0.023167550563812256, Accuracy 98.66666412353516\n",
      "Epoch: 1 - 9000/9843, Loss: 0.03425968810915947, Accuracy 98.67265319824219\n",
      "Epoch: 1 - 9500/9843, Loss: 0.038984015583992004, Accuracy 98.6646728515625\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model.train()\n",
    "\n",
    "print()\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    correct, total = 0, 1\n",
    "    for i, (inputs, targets) in enumerate(dl):\n",
    "        inputs, targets = inputs.mT, targets.mT.reshape(-1)\n",
    "        if i%500==0:\n",
    "            print(f\"Epoch: {epoch+1} - {i}/{len(dl)}, Loss: {loss.item()}, Accuracy {correct/total}\")\n",
    "            correct, total = 0, 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        correct += multi_acc(output_flat, targets)\n",
    "        total += 1\n",
    "        loss = criterion(output_flat, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f4d37a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4039009"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3d5102f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tisuća šesto šezdeset pet, dvadeset osam tisuća šesto šezdeset šest, dvadeset osam tisuća šesto šezdeset sedam, dvadeset osam tisuća šesto šezdeset osam, dvadeset osam tisuća šesto šezdeset devet, dvadeset osam tisuća šesto sedamdeset, dvadeset osam tisuća šesto sedamdeset jedan, dvadeset osam tisuća šesto sedamdeset dva, dvadeset osam tisuća šesto sedamdeset tri, dvadeset osam tisuća šesto sedamdeset četiri, dvadeset osam tisuća šesto sedamdeset pet, dvadeset osam tisuća šesto sedamdeset šest, dvadeset osam tisuća šesto sedamdeset sedam, dvadeset osam tisuća šesto sedamdeset osam, dvadeset osam tisuća šesto sedamdeset devet, dvadeset osam tisuća šesto osamdeset, dvadeset osam tisuća šesto osamdeset jedan, dvadeset osam tisuća šesto osamdeset dva, dvadeset osam tisuća šesto osamdeset tri, dvadeset osam tisuća šesto osamdeset četiri, dvadeset osam tisuća šesto osamdeset pet, dvadeset osam tisuća šesto osamdeset šest, dvadeset osam tisuća šesto osamdeset sedam, dvadeset osam tisuća šest'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1039009: 1039009+1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "df7b1b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sedamdeset jedan , dvadeset osam tisuća šesto sedamdeset dva , dvadeset osam tisuća šesto sedamdeset tri , dvadeset osam tisuća'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'tisuća šesto šezdeset pet, dvadeset osam tisuća šesto šezdeset šest, dvadeset osam tisuća šesto šezdeset sedam, dvadeset osam tisuća šesto šezdeset osam, dvadeset osam tisuća šesto šezdeset devet, dvadeset osam tisuća šesto sedamdeset, dvadeset osam tisuća šesto sedamdeset jedan, dvadeset osam tisuća šesto'\n",
    "\n",
    "def predict(data, pred_len=10):\n",
    "    preds = []\n",
    "    inp = torch.tensor(tokenizer.encode(data).ids, device=device).unsqueeze(0)\n",
    "    print(inp.shape)\n",
    "    for i in range(pred_len):\n",
    "        with torch.no_grad():\n",
    "            inp = inp[:, :seq_len]\n",
    "#             print('>', tokenizer.decode(list(inp.squeeze())))\n",
    "            out = model(inp.mT)\n",
    "#             print(inp[0, -5:])\n",
    "            out = out.log_softmax(dim=2).argmax(dim=2).squeeze()\n",
    "#             print(out.shape)\n",
    "            inp = torch.roll(inp, -1)\n",
    "            inp[0, -1] = out[-1]\n",
    "#             print(out[-1])\n",
    "            preds.append(out[-1])\n",
    "#             for i in range(len(inp)):\n",
    "#                 print(tokenizer.decode(list([inp[i]])), tokenizer.decode(list([out[i]])))\n",
    "    return preds\n",
    "tokenizer.decode(predict(data, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7fb249a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.roll(torch.tensor([1,2,3]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15658536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
